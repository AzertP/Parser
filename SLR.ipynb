{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLR Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an implementation of SLR(1) parser - a bottom-up parser that constructs a parse tree by starting from the input tokens and working towards the start symbol of the grammar. The parser employs first and follow sets to determine valid lookahead tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SLRParser:\n",
    "    \"\"\"\n",
    "    An implementation of SLR(1) parser. This parser constructs parsing tables\n",
    "    and processes context-free grammars using a bottom-up approach with\n",
    "    first and follow set to determine valid lookahead tokens\n",
    "    \"\"\"\n",
    "    def __init__(self, input_grammar, start):\n",
    "        \"\"\"\n",
    "        Initialize the LRParser with a given grammar.\n",
    "\n",
    "        Args:\n",
    "            input_grammar (dict): A dictionary defining the context-free grammar (CFG).\n",
    "        \"\"\"\n",
    "        # Initialize parameters of the CFG\n",
    "        self.grammar = {}\n",
    "        self.start = start\n",
    "        self.terminals = []\n",
    "        self.non_terminals = []\n",
    "        self.dot = \"·\"\n",
    "\n",
    "        self.formattingGrammar(input_grammar)\n",
    "        \n",
    "        self.first_table = {}\n",
    "        self.follow_table = {}\n",
    "        self.in_progress = set()     # this variable is used to avoid left recursive when calculating first\n",
    "        self.calculateFirstTable()\n",
    "        self.calculateFollowTable()\n",
    "        \n",
    "        self.augmented_rules = []    # format of rule: [rhs, [<lhs symbol>, <lhs symbol>, ...]\n",
    "        self.state_map = {}          # store rules of a state (format: state_count: [[rule1], [rule2], ...])\n",
    "        self.state_dict = {}         # store which state go to which state\n",
    "        self.state_count = 0\n",
    "        self.addDot()\n",
    "        self.generateStates()\n",
    "\n",
    "        self.parse_table = []\n",
    "        self.createParseTable()\n",
    "\n",
    "\n",
    "    def formattingGrammar(self, input_grammar):\n",
    "        \"\"\"\n",
    "        Processes the input grammar into an internal representation for the parser.\n",
    "\n",
    "        This method reformats the provided input grammar into a format suitable \n",
    "        for parsing and initializes the grammar rules, start symbol, non-terminals, \n",
    "        and terminals. The first rule in the input grammar is augmented to create \n",
    "        a new start rule.\n",
    "\n",
    "        Args:\n",
    "            input_grammar (dict): The input grammar represented as a dictionary \n",
    "                where keys are non-terminals and values are lists of production rules.\n",
    "\n",
    "        Attributes Modified:\n",
    "            self.grammar (dict)\n",
    "            self.start (str)\n",
    "            self.non_terminals (list)\n",
    "            self.terminals (list)\n",
    "        \"\"\"\n",
    "        # Process the input grammar into a dictionary with each rule have the format of\n",
    "        # key: rulenumber (int) \n",
    "        # value: [lhs (str), rhs (list of symbol)]\n",
    "        count = 0\n",
    "        for key in input_grammar.keys():\n",
    "            # Augment the first rule\n",
    "            if count == 0:\n",
    "                if self.start == \"\":\n",
    "                    self.start = f\"{key}'\"\n",
    "                else:\n",
    "                    self.start = f\"{self.start}'\"\n",
    "                self.grammar[0] = (self.start, [key])\n",
    "                count += 1\n",
    "\n",
    "            # Process each rule into the format above\n",
    "            for rule in input_grammar[key]:\n",
    "                self.grammar[count] = (key, rule)\n",
    "                count += 1\n",
    "\n",
    "        # Detecting terminals and non-terminals symbols if it was not given\n",
    "        if len(self.terminals) == 0 and len(self.non_terminals) == 0:\n",
    "            for key in self.grammar.keys():\n",
    "                lhs, rhs = self.grammar[key]\n",
    "                self.non_terminals.append(lhs)\n",
    "            for key in self.grammar.keys():\n",
    "                lhs, rhs = self.grammar[key]\n",
    "                for sym in rhs:\n",
    "                    if sym not in self.non_terminals and sym not in self.terminals:\n",
    "                        self.terminals.append(sym)\n",
    "\n",
    "\n",
    "    def addDot(self):\n",
    "        \"\"\"\n",
    "        Adding a dot (·) (tracker of process of parsing) at the start of each production's RHS.\n",
    "        \"\"\"\n",
    "        for key in self.grammar.keys():\n",
    "            lhs, rhs = self.grammar[key]\n",
    "            new_rhs = [self.dot]\n",
    "            for elem in rhs:\n",
    "                new_rhs.append(elem)\n",
    "            self.augmented_rules.append([lhs, new_rhs])\n",
    "\n",
    "    def generateStates(self):\n",
    "        \"\"\"\n",
    "        Generate all states for the parser, starting with the initial state.\n",
    "        \"\"\"\n",
    "        # generate and calculate the closure of the initial state I_0\n",
    "        first_state = []\n",
    "        for rule in self.augmented_rules:\n",
    "            if rule[0] == self.start:\n",
    "                first_state.append(rule)\n",
    "        closure_rules = self.findClosure(first_state)\n",
    "        self.state_dict[0] = closure_rules\n",
    "\n",
    "        # generate states until no more state is able to be generated\n",
    "        prev_len = -1\n",
    "        state_completed_GOTO = []\n",
    "        while prev_len != len(self.state_dict):\n",
    "            prev_len = len(self.state_dict)\n",
    "\n",
    "            keys = list(self.state_dict.keys())\n",
    "            for state in keys:\n",
    "                if state not in state_completed_GOTO:\n",
    "                    self.computeGOTO(state)\n",
    "                    state_completed_GOTO.append(state)\n",
    "\n",
    "    \n",
    "    def computeGOTO(self, state):\n",
    "        \"\"\"\n",
    "        Check and manage states that need to compute GOTO transitions\n",
    "\n",
    "        Args:\n",
    "            state (int): The state number.\n",
    "        \"\"\"\n",
    "        generate_new_state_for = []\n",
    "        for rule in self.state_dict[state]:\n",
    "            # if the rule ends with dot (can't shift anymore) => skip\n",
    "            if rule[1][-1] == self.dot:\n",
    "                continue\n",
    "\n",
    "            dot_ind = rule[1].index(self.dot)\n",
    "            next_sym = rule[1][dot_ind+1]\n",
    "\n",
    "            if next_sym not in generate_new_state_for:\n",
    "                generate_new_state_for.append(next_sym)\n",
    "\n",
    "        for sym in generate_new_state_for:\n",
    "            self.GOTO(state, sym)\n",
    "\n",
    "    \n",
    "    def GOTO(self, state, sym):\n",
    "        \"\"\"\n",
    "        Compute the GOTO transitions for a given state.\n",
    "\n",
    "        Args:\n",
    "            state (int): The current state.\n",
    "            sym (str): The grammar symbol.\n",
    "        \"\"\"\n",
    "        new_state = []\n",
    "        for rule in self.state_dict[state]:\n",
    "            # if the rule ends with dot (can't shift anymore) => skip\n",
    "            if rule[1][-1] == self.dot:\n",
    "                continue\n",
    "\n",
    "            dot_ind = rule[1].index(self.dot)\n",
    "            next_sym = rule[1][dot_ind+1]\n",
    "\n",
    "            # shift operation from the previous state of rule on that\n",
    "            if next_sym == sym:\n",
    "                # swap dot with next_sym\n",
    "                shifted_rule = copy.deepcopy(rule)\n",
    "                shifted_rule[1][dot_ind] = shifted_rule[1][dot_ind + 1]\n",
    "                shifted_rule[1][dot_ind + 1] = self.dot\n",
    "                new_state.append(shifted_rule)\n",
    "\n",
    "        closure_rules = self.findClosure(new_state)\n",
    "\n",
    "        # check if state exist\n",
    "        state_exists = -1\n",
    "        for state_num in self.state_dict:\n",
    "            if self.state_dict[state_num] == new_state:\n",
    "                state_exists = state_num\n",
    "                break\n",
    "     \n",
    "        # stateMap is a mapping of GOTO with\n",
    "        # its output states\n",
    "        if state_exists == -1:\n",
    "            self.state_count += 1\n",
    "            self.state_dict[self.state_count] = closure_rules\n",
    "            self.state_map[(state, sym)] = self.state_count\n",
    "        else:\n",
    "            self.state_map[(state, sym)] = state_exists\n",
    "            \n",
    "\n",
    "    def findClosure(self, closure_rules):\n",
    "        \"\"\"\n",
    "        Generate the closure for a rules.\n",
    "\n",
    "        Args:\n",
    "            closure_rules (list): A list of rules for which the closure is to be computed.\n",
    "\n",
    "        Returns:\n",
    "            list: The closure of the input rules.\n",
    "        \"\"\"\n",
    "\n",
    "        # generate closure for the rules in new_state\n",
    "        # generate until can't generate anymore\n",
    "        # start with the closure of the initial state\n",
    "        prev_len = -1\n",
    "        while prev_len != len(closure_rules):\n",
    "            prev_len = len(closure_rules)\n",
    "            for rule in closure_rules:\n",
    "                if rule[1][-1] == self.dot:\n",
    "                    continue\n",
    "                    \n",
    "                dot_ind = rule[1].index(self.dot)\n",
    "                next_sym = rule[1][dot_ind+1]\n",
    "    \n",
    "                # if next_sym is non_terminal then continue adding rule with that nonterminals as lhs\n",
    "                if next_sym in self.non_terminals:\n",
    "                    for augmented_rule in self.augmented_rules:\n",
    "                        if augmented_rule[0] == next_sym and augmented_rule not in closure_rules:\n",
    "                            closure_rules.append(augmented_rule)\n",
    "        return closure_rules\n",
    "\n",
    "        \n",
    "    def calculateFirstTable(self):\n",
    "        \"\"\"\n",
    "        Compute the FIRST table for the grammar.\n",
    "        \"\"\"\n",
    "        for key in self.grammar.keys():\n",
    "            rule = self.grammar[key]\n",
    "            lhs, rhs = rule\n",
    "\n",
    "            if lhs not in self.first_table:\n",
    "                self.first_table[lhs] = list(elem for elem in self.first(rule))\n",
    "            else:\n",
    "                res = self.first(rule)\n",
    "                for elem in res:\n",
    "                    if elem not in self.first_table[lhs]:\n",
    "                        self.first_table[lhs].append(elem)\n",
    "\n",
    "    \n",
    "    def calculateFollowTable(self):\n",
    "        \"\"\"\n",
    "        Compute the FOLLOW table for the grammar.\n",
    "        \"\"\"\n",
    "        for nt in self.non_terminals:\n",
    "            self.follow_table[nt] = self.follow(nt)\n",
    "\n",
    "    \n",
    "    def first(self, rule):\n",
    "        \"\"\"\n",
    "        Compute the FIRST set for a given rule.\n",
    "\n",
    "        Args:\n",
    "            rule (tuple): A tuple (LHS, RHS) representing a grammar rule.\n",
    "\n",
    "        Returns:\n",
    "            list: The FIRST set for the rule.\n",
    "        \"\"\"\n",
    "        lhs, rhs = rule\n",
    "        \n",
    "        if lhs in self.in_progress:\n",
    "            return []  # prevent infinite recursion\n",
    "        \n",
    "        # mark this non-terminal as being processed\n",
    "        self.in_progress.add(lhs)\n",
    "        \n",
    "        # rule for terminals\n",
    "        if rhs[0] in self.terminals:\n",
    "            return [rhs[0]]\n",
    "            \n",
    "        # rule for epsilon\n",
    "        elif rhs[0] == \"#\":\n",
    "            return [\"#\"]\n",
    "            \n",
    "        # rule for non-terminal\n",
    "        else:\n",
    "            res = []\n",
    "            for key in self.grammar.keys():\n",
    "                if rhs[0] == self.grammar[key][0]:\n",
    "                    for elem in self.first(self.grammar[key]):\n",
    "                        res.append(elem) \n",
    "\n",
    "            if \"#\" in res:\n",
    "                res.remove(\"#\")\n",
    "                \n",
    "            self.in_progress.remove(lhs)  # finished processing this non-terminal\n",
    "            return res\n",
    "\n",
    "    \n",
    "    def follow(self, nt, visited=None):\n",
    "        \"\"\"\n",
    "        Compute the FOLLOW set for a non-terminal.\n",
    "\n",
    "        Args:\n",
    "            nt (str): The non-terminal symbol.\n",
    "            visited (set): A set of visited non-terminals to prevent infinite recursion.\n",
    "\n",
    "        Returns:\n",
    "            list: The FOLLOW set for the non-terminal.\n",
    "        \"\"\"\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "    \n",
    "        if nt in visited:\n",
    "            return []\n",
    "\n",
    "        visited.add(nt)\n",
    "        res = set()\n",
    "\n",
    "        # for start symbol return $\n",
    "        if nt == self.start:\n",
    "            res.add(\"$\")\n",
    "\n",
    "        for key in self.grammar.keys():\n",
    "            lhs, rhs = self.grammar[key]\n",
    "            \n",
    "            for i, symbol in enumerate(rhs):\n",
    "                if symbol == nt:\n",
    "                    rhs = rhs[i + 1:]\n",
    "\n",
    "                    # rule 2: there is a symbol after nt\n",
    "                    if len(rhs) != 0:\n",
    "                        # if the symbol after nt is also a non-terminal:\n",
    "                        #   - calculate its first (remove epsilon) and add to res\n",
    "                        #   - if its first contain epsilon, then continue checking the next symbol\n",
    "                        # else the symbol after nt is a terminal:\n",
    "                        #   - then add it to res\n",
    "                        for sym in rhs:\n",
    "                            if sym in self.terminals:\n",
    "                                res.add(sym)\n",
    "                                break\n",
    "                            elif sym in self.first_table:\n",
    "                                first_sym = self.first_table[sym]\n",
    "                                res.update(set(first_sym) - {\"#\"})\n",
    "    \n",
    "                                if \"#\" in first_sym:\n",
    "                                    res.remove(\"#\")\n",
    "                                else:\n",
    "                                    break\n",
    "\n",
    "                    # rule 3: there is no symbol after nt -> FOLLOW(lhs) ⊆ FOLLOW(nt)\n",
    "                    if len(rhs) == 0:  \n",
    "                        if lhs != nt:\n",
    "                            res.update(self.follow(lhs, visited))\n",
    "                            \n",
    "        visited.remove(nt)\n",
    "        return list(res)\n",
    "\n",
    "    def createParseTable(self):\n",
    "        \"\"\"\n",
    "        Create the parsing table for the SLR(1) parser.\n",
    "        \"\"\"\n",
    "        rows = list(self.state_dict.keys())\n",
    "        cols = self.terminals + [\"$\"] + self.non_terminals\n",
    "\n",
    "        # create empty table\n",
    "        temp_row = []\n",
    "        for i in range(len(cols)):\n",
    "            temp_row.append([])\n",
    "        for i in range(len(rows)):\n",
    "            self.parse_table.append(copy.deepcopy(temp_row))\n",
    "\n",
    "        # add shift and goto entries to table\n",
    "        for entry in self.state_map.keys():\n",
    "            state = entry[0]\n",
    "            sym = entry[1]\n",
    "\n",
    "            row_ind = rows.index(state)\n",
    "            col_ind = cols.index(sym)\n",
    "\n",
    "            if sym in self.terminals:\n",
    "                self.parse_table[row_ind][col_ind].append(f\"S{self.state_map[entry]}\")\n",
    "            elif sym in self.non_terminals:\n",
    "                self.parse_table[row_ind][col_ind].append(f\"G{self.state_map[entry]}\")\n",
    "\n",
    "        # add reduce to table\n",
    "        for state in self.state_dict.keys():\n",
    "            for rule in self.state_dict[state]:\n",
    "                # if the rule is a handle -> add reduce correspondingly\n",
    "                if rule[1][-1] == self.dot:\n",
    "                    copy_rhs = copy.deepcopy(rule[1])\n",
    "                    copy_rhs.remove(self.dot)\n",
    "\n",
    "                    # add entry R_rule_num (Reduce -> rule_num) to entry (state, follow(rhs)) in parse table\n",
    "                    for rule_num in self.grammar.keys():\n",
    "                        if self.grammar[rule_num][0] == rule[0] and self.grammar[rule_num][1] == copy_rhs:\n",
    "                            for follow in self.follow_table[rule[0]]:\n",
    "                                row_ind = rows.index(state)\n",
    "                                col_ind = cols.index(follow)\n",
    "                                if rule_num == 0:\n",
    "                                    self.parse_table[row_ind][col_ind].append(\"Accept\")\n",
    "                                else:\n",
    "                                    self.parse_table[row_ind][col_ind].append(f\"R{rule_num}\")\n",
    "\n",
    "    \t# printing table\n",
    "        print(\"\\nParsing table:\\n\")\n",
    "        frmt = \"{:>8}\" * len(cols)\n",
    "        print(\" \", frmt.format(*cols), \"\\n\")\n",
    "        ptr = 0\n",
    "        j = 0\n",
    "        for y in self.parse_table:\n",
    "            # frmt1 = \"{:>8}\"\n",
    "            print(f\"{{:>3}}\".format('I'+str(j)), end=\"\")\n",
    "            for e in y:\n",
    "                print(f\"{{:>8}}\".format(\"/\".join(e)), end=\"\")\n",
    "            print()\n",
    "            j += 1\n",
    "\n",
    "        # saving the parse table to a csv file\n",
    "        file = open(\"rules/parse_tables/parsetable1.csv\", \"w\")\n",
    "        file.write(\"state,\"+\",\".join(cols)+\"\\n\")\n",
    "        j = 0\n",
    "        for y in self.parse_table:\n",
    "            line = \"\"\n",
    "            line += f\"I{j}\"\n",
    "            for e in y:\n",
    "                line += \",\" + \"/\".join(e)\n",
    "            file.write(line + \"\\n\")\n",
    "            j += 1\n",
    "        file.close()\n",
    "\n",
    "    def parse(self, input_string):\n",
    "        \"\"\"\n",
    "        Parses the given input string using the constructed SLR parse table.\n",
    "\n",
    "        Args:\n",
    "            input_string (list): The input string represented as a list of symbols \n",
    "                (terminals) to be parsed. The end of the input is marked by \"$\".\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the input string is successfully parsed and reaches \n",
    "                the \"Accept\" state; False otherwise.\n",
    "\n",
    "        Notes: This method handles conflicts by always selecting the first operation \n",
    "        in a conflicting cell in the parse table.\n",
    "        \"\"\"\n",
    "        # self.printResultAndGoto()\n",
    "        rows = list(self.state_dict.keys())\n",
    "        cols = self.terminals + [\"$\"] + self.non_terminals\n",
    "        \n",
    "        # appends \"$\" to indicate the end of input.\n",
    "        ls_input = input_string + [\"$\"]\n",
    "        current_char = ls_input[0]\n",
    "        ls_output = []\n",
    "        stack = [0]\n",
    "        while True:\n",
    "            if current_char not in cols:\n",
    "                return False\n",
    "            \n",
    "            row_ind = rows.index(stack[-1])\n",
    "            col_ind = cols.index(current_char)\n",
    "            \n",
    "            operation = self.parse_table[row_ind][col_ind]\n",
    "            \n",
    "            if operation == []:\n",
    "                return False\n",
    "                \n",
    "            else:\n",
    "                operation = operation[0] # just get the first operation in conflict cell\n",
    "                if operation[0] == \"R\":\n",
    "                    rule_num = int(operation[1:])\n",
    "                    current_char = self.grammar[rule_num][0]\n",
    "                    \n",
    "                    # pop stack equal to number of char on rhs of reduce rule\n",
    "                    stack_pop_count = len(self.grammar[rule_num][1])\n",
    "                    stack = stack[:-stack_pop_count]\n",
    "\n",
    "                    ls_output.append(rule_num)\n",
    "                \n",
    "                # goto operation\n",
    "                elif operation[0] == \"G\":\n",
    "                    stack.append(int(operation[1:]))\n",
    "                    current_char = ls_input[0]  \n",
    "                    \n",
    "                # shift operation\n",
    "                elif operation[0] == \"S\":\n",
    "                    stack.append(int(operation[1:]))\n",
    "                    ls_input.pop(0) \n",
    "                    current_char = ls_input[0]      \n",
    "\n",
    "                # accept reached\n",
    "                elif operation == \"Accept\":\n",
    "                    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# class SLRParser(LRParser):\n",
    "#     def __init__(self, grammar, terminals, non_terminals, start, dot):\n",
    "#         super().__init__(grammar, terminals, non_terminals, start, dot)\n",
    "\n",
    "#     def parse(self, input_string):\n",
    "#         # self.printResultAndGoto()\n",
    "#         rows = list(self.state_dict.keys())\n",
    "#         cols = self.terminals + [\"$\"] + self.non_terminals\n",
    "        \n",
    "#         ls_input = input_string + [\"$\"]\n",
    "#         current_char = ls_input[0]\n",
    "#         ls_output = []\n",
    "#         stack = [0]\n",
    "#         while True:\n",
    "#             # print(ls_input, current_char, stack)\n",
    "#             # time.sleep(1)\n",
    "#             if current_char not in cols:\n",
    "#                 return False\n",
    "            \n",
    "#             row_ind = rows.index(stack[-1])\n",
    "#             col_ind = cols.index(current_char)\n",
    "            \n",
    "#             operation = self.parse_table[row_ind][col_ind]\n",
    "            \n",
    "#             if operation == []:\n",
    "#                 return False\n",
    "                \n",
    "#             else:\n",
    "#                 operation = operation[0] # just get the first operation in conflict cell\n",
    "#                 # print(operation)\n",
    "#                 # reduce operation\n",
    "#                 if operation[0] == \"R\":\n",
    "#                     rule_num = int(operation[1:])\n",
    "#                     current_char = self.grammar[rule_num][0]\n",
    "                    \n",
    "#                     # pop stack equal to number of char on rhs of reduce rule\n",
    "#                     stack_pop_count = len(self.grammar[rule_num][1])\n",
    "#                     stack = stack[:-stack_pop_count]\n",
    "\n",
    "#                     ls_output.append(rule_num)\n",
    "                \n",
    "#                 # goto operation\n",
    "#                 elif operation[0] == \"G\":\n",
    "#                     stack.append(int(operation[1:]))\n",
    "#                     current_char = ls_input[0]  \n",
    "                    \n",
    "#                 # shift operation\n",
    "#                 elif operation[0] == \"S\":\n",
    "#                     stack.append(int(operation[1:]))\n",
    "#                     ls_input.pop(0) \n",
    "#                     current_char = ls_input[0]      \n",
    "\n",
    "#                 # accept reached\n",
    "#                 elif operation == \"Accept\":\n",
    "#                     return True\n",
    "\n",
    "    \n",
    "# # Example 1 Grammar and Tables\n",
    "# grammar = {\n",
    "#     0: (\"E'\", [\"E\"]),                # Rule 0: E'→ E\n",
    "#     1: (\"E\", [\"E\", \"+\", \"T\"]),       # Rule 1: E → E + T\n",
    "#     2: (\"E\", [\"T\"]),                 # Rule 2: E → T\n",
    "#     3: (\"T\", [\"T\", \"*\", \"F\"]),       # Rule 3: T → T * F\n",
    "#     4: (\"T\", [\"F\"]),                 # Rule 4: T → F\n",
    "#     5: (\"F\", [\"(\", \"E\", \")\"]),       # Rule 5: F → ( E )\n",
    "#     6: (\"F\", [\"a\"]),                 # Rule 6: F → a\n",
    "    \n",
    "# }\n",
    "\n",
    "# terminals = [\"a\", \"+\", \"*\",\"(\", \")\"]\n",
    "# non_terminals = [\"E'\", \"E\", \"T\", \"F\"]\n",
    "# start = \"E'\"\n",
    "# dot = '·'\n",
    "\n",
    "# # Test the Parser\n",
    "# parser = SLRParser(grammar, terminals, non_terminals, start, dot)\n",
    "# input_string = list(\"a*a+a*a+a\")\n",
    "# res = parser.parse(input_string)\n",
    "\n",
    "# print()\n",
    "# if res == False:\n",
    "#     print(f\"Input not accepted - {''.join(input_string)}\")\n",
    "# else:\n",
    "#     print(f\"Input accepted - {''.join(input_string)}\")\n",
    "\n",
    "\n",
    "\n",
    "# # # Example 2 Grammar and Tables\n",
    "# # grammar = {\n",
    "# #     0: (\"S'\", [\"S\"]),\n",
    "# #     1: (\"S\", [\"L\", \"=\", \"R\"]),    # Rule 1: S → L = R\n",
    "# #     2: (\"S\", [\"R\"]),              # Rule 2: S → R\n",
    "# #     3: (\"L\", [\"*\", \"R\"]),         # Rule 3: L → * R\n",
    "# #     4: (\"L\", [\"a\"]),              # Rule 4: L → a\n",
    "# #     5: (\"R\", [\"L\"]),              # Rule 5: R → L\n",
    "# # }\n",
    "\n",
    "# # terminals = [\"a\", \"=\", \"*\"]\n",
    "# # non_terminals = [\"S'\", \"S\", \"L\", \"R\"]\n",
    "# # start = \"S'\"\n",
    "# # dot = '·'\n",
    "\n",
    "# # # Test the Parser\n",
    "# # parser = SLRParser(grammar, terminals, non_terminals, start, dot)\n",
    "# # # input_string = list(\"a=a\")\n",
    "\n",
    "# # # parser.parse(input_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing - K-path coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing table:\n",
      "\n",
      "         +       *       (       )       a       $      E'       E       E       T       T       F       F \n",
      "\n",
      " I0                      S4              S5                      G1              G2              G3        \n",
      " I1      S6                                  Accept                                                        \n",
      " I2      R2      S7              R2              R2                                                        \n",
      " I3      R4      R4              R4              R4                                                        \n",
      " I4                      S4              S5                      G8              G2              G3        \n",
      " I5      R6      R6              R6              R6                                                        \n",
      " I6                      S4              S5                                      G9              G3        \n",
      " I7                      S4              S5                                                     G10        \n",
      " I8      S6                     S11                                                                        \n",
      " I9      R1      S7              R1              R1                                                        \n",
      "I10      R3      R3              R3              R3                                                        \n",
      "I11      R5      R5              R5              R5                                                        \n",
      "\n",
      "Parsing table:\n",
      "\n",
      "         =       *       a       $      S'       S       S       L       L       R \n",
      "\n",
      " I0              S4      S5                      G1              G2              G3\n",
      " I1                          Accept                                                \n",
      " I2   S6/R5                      R5                                                \n",
      " I3                              R2                                                \n",
      " I4              S4      S5                                      G8              G7\n",
      " I5      R4                      R4                                                \n",
      " I6              S4      S5                                      G8              G9\n",
      " I7      R3                      R3                                                \n",
      " I8      R5                      R5                                                \n",
      " I9                              R1                                                \n"
     ]
    }
   ],
   "source": [
    "import simplefuzzer as fuzzer\n",
    "\n",
    "def parents(g):\n",
    "    parent = {}\n",
    "    for k in g:\n",
    "        for r in g[k]:\n",
    "            for t in r:\n",
    "                if t not in g: continue\n",
    "                if t not in parent: parent[t] = set()\n",
    "                parent[t].add(k)\n",
    "    return parent\n",
    "\n",
    "\n",
    "def _k_paths(g, k, parent):\n",
    "    if k == 1: return [[k] for k in g]\n",
    "    _k_1_paths = _k_paths(g, k-1, parent)\n",
    "    # attach parents to each of the _k_1_paths.\n",
    "    new_paths = []\n",
    "    for path in _k_1_paths:\n",
    "        if path[0] not in parent: continue\n",
    "        for p in parent[path[0]]:\n",
    "            new_paths.append([p] + path)\n",
    "    return new_paths\n",
    "\n",
    "\n",
    "def k_paths(g, k):\n",
    "    g_parents = parents(g)\n",
    "    return _k_paths(g, k, g_parents)\n",
    "\n",
    "\n",
    "def find_rule_containing_key(g, key, root):\n",
    "    leaf = root[0]\n",
    "    for rule in g[key]:\n",
    "        r = []\n",
    "        while rule:\n",
    "            token, *rule = rule\n",
    "            if leaf != token:\n",
    "                r.append((token, None))\n",
    "            else:\n",
    "                return r + [root] + [(t, None) for t in rule]\n",
    "    assert False\n",
    "\n",
    "\n",
    "def path_to_tree(path_, g):\n",
    "    leaf, *path = reversed(path_)\n",
    "    root = (leaf, [])\n",
    "    # take the lowest\n",
    "    while path:\n",
    "        leaf, *path = path\n",
    "        if not path: return root\n",
    "        rule = find_rule_containing_key(g, leaf, root)\n",
    "        root = [leaf, rule]\n",
    "\n",
    "def tree_fill_(g, pt, f):\n",
    "    key, children = pt\n",
    "    if not children:\n",
    "        if key in g:\n",
    "            return (key, [(f.fuzz(key), [])])\n",
    "        else:\n",
    "            return (key, [])\n",
    "    else:\n",
    "        return (key, [tree_fill_(g, c, f) for c in children])\n",
    "\n",
    "\n",
    "def tree_fill(g, pt):\n",
    "    rgf = fuzzer.LimitFuzzer(g)\n",
    "    return tree_fill_(g, pt, rgf)\n",
    "\n",
    "\n",
    "def collapse(t):\n",
    "    key, children = t\n",
    "    if not children:\n",
    "        return key\n",
    "    return ''.join([collapse(c) for c in children])\n",
    "\n",
    "def display_tree(node, level=0, c='-'):\n",
    "    key, children = node\n",
    "    if children is None:\n",
    "        print(' ' * 4 * level + c+'> ' + key)\n",
    "    else:\n",
    "        print(' ' * 4 * level + c+'> ' + key)\n",
    "        for c in children:\n",
    "            if isinstance(c, str):\n",
    "                print(' ' * 4 * (level+1) + c)\n",
    "            else:\n",
    "                display_tree(c, level + 1, c='+')\n",
    "\n",
    "\n",
    "def test_valid_k_path_1():\n",
    "    # Example 1 Grammar and Tables\n",
    "    grammar = {\n",
    "        \"E\": [\n",
    "            [\"E\", \"+\", \"T\"],       # Rule 1: E → E + T\n",
    "            [\"T\"]                  # Rule 2: E → T\n",
    "            ],        \n",
    "        \"T\": [\n",
    "            [\"T\", \"*\", \"F\"],       # Rule 3: T → T * F\n",
    "            [\"F\"]                  # Rule 4: T → F\n",
    "            ],           \n",
    "        \"F\": [\n",
    "            [\"(\", \"E\", \")\"],       # Rule 5: F → ( E )\n",
    "            [\"a\"]                  # Rule 6: F → a\n",
    "            ]\n",
    "    }\n",
    "\n",
    "    start = \"E\"\n",
    "\n",
    "    parser = SLRParser(grammar, start)\n",
    "\n",
    "    # Test the parser\n",
    "    for path in k_paths(grammar, 5):\n",
    "        if path[0] in start: \n",
    "            # print(path)\n",
    "            tree = path_to_tree(path, grammar)\n",
    "            # print(tree)\n",
    "            for i in range(100):\n",
    "                t = tree_fill(grammar, tree)\n",
    "                s = collapse(t)\n",
    "                res = parser.parse(list(s))\n",
    "                assert res == True, f\"Fail test: {s}\"\n",
    "\n",
    "\n",
    "def test_valid_k_path_2():\n",
    "    # Example 2 Grammar and Tables\n",
    "    grammar = {\n",
    "        \"S\": [\n",
    "              [\"L\", \"=\", \"R\"],    # Rule 1: S → L = R\n",
    "              [\"R\"]               # Rule 2: S → R\n",
    "             ],\n",
    "        \"L\": [\n",
    "              [\"*\", \"R\"],         # Rule 3: L → * R\n",
    "              [\"a\"]               # Rule 4: L → a\n",
    "             ],\n",
    "        \"R\": [\n",
    "              [\"L\"]               # Rule 5: R → L\n",
    "             ]\n",
    "    }\n",
    "    start = \"S\"\n",
    "\n",
    "    parser = SLRParser(grammar, start)\n",
    "\n",
    "    # Test the parser\n",
    "    for path in k_paths(grammar, 5):\n",
    "        if path[0] in start: \n",
    "            # print(path)\n",
    "            tree = path_to_tree(path, grammar)\n",
    "            # print(tree)\n",
    "            for i in range(100):\n",
    "                t = tree_fill(grammar, tree)\n",
    "                s = collapse(t)\n",
    "                res = parser.parse(list(s))\n",
    "                assert res == True, f\"Fail test: {s}\"\n",
    "\n",
    "\n",
    "test_valid_k_path_1()\n",
    "test_valid_k_path_2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
