{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. GLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class SLRParser:\n",
        "    \"\"\"\n",
        "    An implementation of SLR(1) parser. This parser constructs parsing tables\n",
        "    and processes context-free grammars using a bottom-up approach with\n",
        "    first and follow set to determine valid lookahead tokens\n",
        "    \"\"\"\n",
        "    def __init__(self, input_grammar, start):\n",
        "        \"\"\"\n",
        "        Initialize the LRParser with a given grammar.\n",
        "\n",
        "        Args:\n",
        "            input_grammar (dict): A dictionary defining the context-free grammar (CFG).\n",
        "        \"\"\"\n",
        "        # Initialize parameters of the CFG\n",
        "        self.grammar = {}\n",
        "        self.start = start\n",
        "        self.terminals = []\n",
        "        self.non_terminals = []\n",
        "        self.dot = \"·\"\n",
        "\n",
        "        self.formattingGrammar(input_grammar)\n",
        "        \n",
        "        self.first_table = {}\n",
        "        self.follow_table = {}\n",
        "        self.in_progress = set()     # this variable is used to avoid left recursive when calculating first\n",
        "        self.calculateFirstTable()\n",
        "        self.calculateFollowTable()\n",
        "        \n",
        "        self.augmented_rules = []    # format of rule: [rhs, [<lhs symbol>, <lhs symbol>, ...]\n",
        "        self.state_map = {}          # store rules of a state (format: state_count: [[rule1], [rule2], ...])\n",
        "        self.state_dict = {}         # store which state go to which state\n",
        "        self.state_count = 0\n",
        "        self.addDot()\n",
        "        self.generateStates()\n",
        "\n",
        "        self.parse_table = []\n",
        "        self.createParseTable()\n",
        "\n",
        "\n",
        "    def formattingGrammar(self, input_grammar):\n",
        "        \"\"\"\n",
        "        Processes the input grammar into an internal representation for the parser.\n",
        "\n",
        "        This method reformats the provided input grammar into a format suitable \n",
        "        for parsing and initializes the grammar rules, start symbol, non-terminals, \n",
        "        and terminals. The first rule in the input grammar is augmented to create \n",
        "        a new start rule.\n",
        "\n",
        "        Args:\n",
        "            input_grammar (dict): The input grammar represented as a dictionary \n",
        "                where keys are non-terminals and values are lists of production rules.\n",
        "\n",
        "        Attributes Modified:\n",
        "            self.grammar (dict)\n",
        "            self.start (str)\n",
        "            self.non_terminals (list)\n",
        "            self.terminals (list)\n",
        "        \"\"\"\n",
        "        # Process the input grammar into a dictionary with each rule have the format of\n",
        "        # key: rulenumber (int) \n",
        "        # value: [lhs (str), rhs (list of symbol)]\n",
        "        count = 0\n",
        "        for key in input_grammar.keys():\n",
        "            # Augment the first rule\n",
        "            if count == 0:\n",
        "                if self.start == \"\":\n",
        "                    self.start = f\"{key}'\"\n",
        "                else:\n",
        "                    self.start = f\"{self.start}'\"\n",
        "                self.grammar[0] = (self.start, [key])\n",
        "                count += 1\n",
        "\n",
        "            # Process each rule into the format above\n",
        "            for rule in input_grammar[key]:\n",
        "                self.grammar[count] = (key, rule)\n",
        "                count += 1\n",
        "\n",
        "        # Detecting terminals and non-terminals symbols if it was not given\n",
        "        if len(self.terminals) == 0 and len(self.non_terminals) == 0:\n",
        "            for key in self.grammar.keys():\n",
        "                lhs, rhs = self.grammar[key]\n",
        "                if lhs not in self.non_terminals and lhs not in self.terminals:\n",
        "                    self.non_terminals.append(lhs)\n",
        "            for key in self.grammar.keys():\n",
        "                lhs, rhs = self.grammar[key]\n",
        "                for sym in rhs:\n",
        "                    if sym not in self.non_terminals and sym not in self.terminals:\n",
        "                        self.terminals.append(sym)\n",
        "\n",
        "\n",
        "    def addDot(self):\n",
        "        \"\"\"\n",
        "        Adding a dot (·) (tracker of process of parsing) at the start of each production's RHS.\n",
        "        \"\"\"\n",
        "        for key in self.grammar.keys():\n",
        "            lhs, rhs = self.grammar[key]\n",
        "            new_rhs = [self.dot]\n",
        "            for elem in rhs:\n",
        "                new_rhs.append(elem)\n",
        "            self.augmented_rules.append([lhs, new_rhs])\n",
        "\n",
        "    def generateStates(self):\n",
        "        \"\"\"\n",
        "        Generate all states for the parser, starting with the initial state.\n",
        "        \"\"\"\n",
        "        # generate and calculate the closure of the initial state I_0\n",
        "        first_state = []\n",
        "        for rule in self.augmented_rules:\n",
        "            if rule[0] == self.start:\n",
        "                first_state.append(rule)\n",
        "        closure_rules = self.findClosure(first_state)\n",
        "        self.state_dict[0] = closure_rules\n",
        "\n",
        "        # generate states until no more state is able to be generated\n",
        "        prev_len = -1\n",
        "        state_completed_GOTO = []\n",
        "        while prev_len != len(self.state_dict):\n",
        "            prev_len = len(self.state_dict)\n",
        "\n",
        "            keys = list(self.state_dict.keys())\n",
        "            for state in keys:\n",
        "                if state not in state_completed_GOTO:\n",
        "                    self.computeGOTO(state)\n",
        "                    state_completed_GOTO.append(state)\n",
        "\n",
        "    \n",
        "    def computeGOTO(self, state):\n",
        "        \"\"\"\n",
        "        Check and manage states that need to compute GOTO transitions\n",
        "\n",
        "        Args:\n",
        "            state (int): The state number.\n",
        "        \"\"\"\n",
        "        generate_new_state_for = []\n",
        "        for rule in self.state_dict[state]:\n",
        "            # if the rule ends with dot (can't shift anymore) => skip\n",
        "            if rule[1][-1] == self.dot:\n",
        "                continue\n",
        "\n",
        "            dot_ind = rule[1].index(self.dot)\n",
        "            next_sym = rule[1][dot_ind+1]\n",
        "\n",
        "            if next_sym not in generate_new_state_for:\n",
        "                generate_new_state_for.append(next_sym)\n",
        "\n",
        "        for sym in generate_new_state_for:\n",
        "            self.GOTO(state, sym)\n",
        "\n",
        "    \n",
        "    def GOTO(self, state, sym):\n",
        "        \"\"\"\n",
        "        Compute the GOTO transitions for a given state.\n",
        "\n",
        "        Args:\n",
        "            state (int): The current state.\n",
        "            sym (str): The grammar symbol.\n",
        "        \"\"\"\n",
        "        new_state = []\n",
        "        for rule in self.state_dict[state]:\n",
        "            # if the rule ends with dot (can't shift anymore) => skip\n",
        "            if rule[1][-1] == self.dot:\n",
        "                continue\n",
        "\n",
        "            dot_ind = rule[1].index(self.dot)\n",
        "            next_sym = rule[1][dot_ind+1]\n",
        "\n",
        "            # shift operation from the previous state of rule on that\n",
        "            if next_sym == sym:\n",
        "                # swap dot with next_sym\n",
        "                shifted_rule = copy.deepcopy(rule)\n",
        "                shifted_rule[1][dot_ind] = shifted_rule[1][dot_ind + 1]\n",
        "                shifted_rule[1][dot_ind + 1] = self.dot\n",
        "                new_state.append(shifted_rule)\n",
        "\n",
        "        closure_rules = self.findClosure(new_state)\n",
        "\n",
        "        # check if state exist\n",
        "        state_exists = -1\n",
        "        for state_num in self.state_dict:\n",
        "            if self.state_dict[state_num] == new_state:\n",
        "                state_exists = state_num\n",
        "                break\n",
        "     \n",
        "        # stateMap is a mapping of GOTO with\n",
        "        # its output states\n",
        "        if state_exists == -1:\n",
        "            self.state_count += 1\n",
        "            self.state_dict[self.state_count] = closure_rules\n",
        "            self.state_map[(state, sym)] = self.state_count\n",
        "        else:\n",
        "            self.state_map[(state, sym)] = state_exists\n",
        "            \n",
        "\n",
        "    def findClosure(self, closure_rules):\n",
        "        \"\"\"\n",
        "        Generate the closure for a rules.\n",
        "\n",
        "        Args:\n",
        "            closure_rules (list): A list of rules for which the closure is to be computed.\n",
        "\n",
        "        Returns:\n",
        "            list: The closure of the input rules.\n",
        "        \"\"\"\n",
        "\n",
        "        # generate closure for the rules in new_state\n",
        "        # generate until can't generate anymore\n",
        "        # start with the closure of the initial state\n",
        "        prev_len = -1\n",
        "        while prev_len != len(closure_rules):\n",
        "            prev_len = len(closure_rules)\n",
        "            for rule in closure_rules:\n",
        "                if rule[1][-1] == self.dot:\n",
        "                    continue\n",
        "                    \n",
        "                dot_ind = rule[1].index(self.dot)\n",
        "                next_sym = rule[1][dot_ind+1]\n",
        "    \n",
        "                # if next_sym is non_terminal then continue adding rule with that nonterminals as lhs\n",
        "                if next_sym in self.non_terminals:\n",
        "                    for augmented_rule in self.augmented_rules:\n",
        "                        if augmented_rule[0] == next_sym and augmented_rule not in closure_rules:\n",
        "                            closure_rules.append(augmented_rule)\n",
        "        return closure_rules\n",
        "\n",
        "        \n",
        "    def calculateFirstTable(self):\n",
        "        \"\"\"\n",
        "        Compute the FIRST table for the grammar.\n",
        "        \"\"\"\n",
        "        for key in self.grammar.keys():\n",
        "            rule = self.grammar[key]\n",
        "            lhs, rhs = rule\n",
        "\n",
        "            if lhs not in self.first_table:\n",
        "                self.first_table[lhs] = list(elem for elem in self.first(rule))\n",
        "            else:\n",
        "                res = self.first(rule)\n",
        "                for elem in res:\n",
        "                    if elem not in self.first_table[lhs]:\n",
        "                        self.first_table[lhs].append(elem)\n",
        "\n",
        "    \n",
        "    def calculateFollowTable(self):\n",
        "        \"\"\"\n",
        "        Compute the FOLLOW table for the grammar.\n",
        "        \"\"\"\n",
        "        for nt in self.non_terminals:\n",
        "            self.follow_table[nt] = self.follow(nt)\n",
        "\n",
        "    \n",
        "    def first(self, rule):\n",
        "        \"\"\"\n",
        "        Compute the FIRST set for a given rule.\n",
        "\n",
        "        Args:\n",
        "            rule (tuple): A tuple (LHS, RHS) representing a grammar rule.\n",
        "\n",
        "        Returns:\n",
        "            list: The FIRST set for the rule.\n",
        "        \"\"\"\n",
        "        lhs, rhs = rule\n",
        "        \n",
        "        if lhs in self.in_progress:\n",
        "            return []  # prevent infinite recursion\n",
        "        \n",
        "        # mark this non-terminal as being processed\n",
        "        self.in_progress.add(lhs)\n",
        "        \n",
        "        # rule for terminals\n",
        "        if rhs[0] in self.terminals:\n",
        "            return [rhs[0]]\n",
        "            \n",
        "        # rule for epsilon\n",
        "        elif rhs[0] == \"#\":\n",
        "            return [\"#\"]\n",
        "            \n",
        "        # rule for non-terminal\n",
        "        else:\n",
        "            res = []\n",
        "            for key in self.grammar.keys():\n",
        "                if rhs[0] == self.grammar[key][0]:\n",
        "                    for elem in self.first(self.grammar[key]):\n",
        "                        res.append(elem) \n",
        "\n",
        "            if \"#\" in res:\n",
        "                res.remove(\"#\")\n",
        "                \n",
        "            self.in_progress.remove(lhs)  # finished processing this non-terminal\n",
        "            return res\n",
        "\n",
        "    \n",
        "    def follow(self, nt, visited=None):\n",
        "        \"\"\"\n",
        "        Compute the FOLLOW set for a non-terminal.\n",
        "\n",
        "        Args:\n",
        "            nt (str): The non-terminal symbol.\n",
        "            visited (set): A set of visited non-terminals to prevent infinite recursion.\n",
        "\n",
        "        Returns:\n",
        "            list: The FOLLOW set for the non-terminal.\n",
        "        \"\"\"\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "    \n",
        "        if nt in visited:\n",
        "            return []\n",
        "\n",
        "        visited.add(nt)\n",
        "        res = set()\n",
        "\n",
        "        # for start symbol return $\n",
        "        if nt == self.start:\n",
        "            res.add(\"$\")\n",
        "\n",
        "        for key in self.grammar.keys():\n",
        "            lhs, rhs = self.grammar[key]\n",
        "            \n",
        "            for i, symbol in enumerate(rhs):\n",
        "                if symbol == nt:\n",
        "                    rhs = rhs[i + 1:]\n",
        "\n",
        "                    # rule 2: there is a symbol after nt\n",
        "                    if len(rhs) != 0:\n",
        "                        # if the symbol after nt is also a non-terminal:\n",
        "                        #   - calculate its first (remove epsilon) and add to res\n",
        "                        #   - if its first contain epsilon, then continue checking the next symbol\n",
        "                        # else the symbol after nt is a terminal:\n",
        "                        #   - then add it to res\n",
        "                        for sym in rhs:\n",
        "                            if sym in self.terminals:\n",
        "                                res.add(sym)\n",
        "                                break\n",
        "                            elif sym in self.first_table:\n",
        "                                first_sym = self.first_table[sym]\n",
        "                                res.update(set(first_sym) - {\"#\"})\n",
        "    \n",
        "                                if \"#\" in first_sym:\n",
        "                                    res.remove(\"#\")\n",
        "                                else:\n",
        "                                    break\n",
        "\n",
        "                    # rule 3: there is no symbol after nt -> FOLLOW(lhs) ⊆ FOLLOW(nt)\n",
        "                    if len(rhs) == 0:  \n",
        "                        if lhs != nt:\n",
        "                            res.update(self.follow(lhs, visited))\n",
        "                            \n",
        "        visited.remove(nt)\n",
        "        return list(res)\n",
        "\n",
        "    def createParseTable(self):\n",
        "        \"\"\"\n",
        "        Create the parsing table for the SLR(1) parser.\n",
        "        \"\"\"\n",
        "        rows = list(self.state_dict.keys())\n",
        "        cols = self.terminals + [\"$\"] + self.non_terminals\n",
        "\n",
        "        # create empty table\n",
        "        temp_row = []\n",
        "        for i in range(len(cols)):\n",
        "            temp_row.append([])\n",
        "        for i in range(len(rows)):\n",
        "            self.parse_table.append(copy.deepcopy(temp_row))\n",
        "\n",
        "        # add shift and goto entries to table\n",
        "        for entry in self.state_map.keys():\n",
        "            state = entry[0]\n",
        "            sym = entry[1]\n",
        "\n",
        "            row_ind = rows.index(state)\n",
        "            col_ind = cols.index(sym)\n",
        "\n",
        "            if sym in self.terminals:\n",
        "                self.parse_table[row_ind][col_ind].append(f\"S{self.state_map[entry]}\")\n",
        "            elif sym in self.non_terminals:\n",
        "                self.parse_table[row_ind][col_ind].append(f\"G{self.state_map[entry]}\")\n",
        "\n",
        "        # add reduce to table\n",
        "        for state in self.state_dict.keys():\n",
        "            for rule in self.state_dict[state]:\n",
        "                # if the rule is a handle -> add reduce correspondingly\n",
        "                if rule[1][-1] == self.dot:\n",
        "                    copy_rhs = copy.deepcopy(rule[1])\n",
        "                    copy_rhs.remove(self.dot)\n",
        "\n",
        "                    # add entry R_rule_num (Reduce -> rule_num) to entry (state, follow(rhs)) in parse table\n",
        "                    for rule_num in self.grammar.keys():\n",
        "                        if self.grammar[rule_num][0] == rule[0] and self.grammar[rule_num][1] == copy_rhs:\n",
        "                            for follow in self.follow_table[rule[0]]:\n",
        "                                row_ind = rows.index(state)\n",
        "                                col_ind = cols.index(follow)\n",
        "                                if rule_num == 0:\n",
        "                                    self.parse_table[row_ind][col_ind].append(\"Accept\")\n",
        "                                else:\n",
        "                                    self.parse_table[row_ind][col_ind].append(f\"R{rule_num}\")\n",
        "\n",
        "    \t# printing table\n",
        "        print(\"\\nParsing table:\\n\")\n",
        "        frmt = \"{:>8}\" * len(cols)\n",
        "        print(\" \", frmt.format(*cols), \"\\n\")\n",
        "        ptr = 0\n",
        "        j = 0\n",
        "        for y in self.parse_table:\n",
        "            # frmt1 = \"{:>8}\"\n",
        "            print(f\"{{:>3}}\".format('I'+str(j)), end=\"\")\n",
        "            for e in y:\n",
        "                print(f\"{{:>8}}\".format(\"/\".join(e)), end=\"\")\n",
        "            print()\n",
        "            j += 1\n",
        "\n",
        "        # saving the parse table to a csv file\n",
        "        file = open(\"rules/parse_tables/parsetable1.csv\", \"w\")\n",
        "        file.write(\"state,\"+\",\".join(cols)+\"\\n\")\n",
        "        j = 0\n",
        "        for y in self.parse_table:\n",
        "            line = \"\"\n",
        "            line += f\"I{j}\"\n",
        "            for e in y:\n",
        "                line += \",\" + \"/\".join(e)\n",
        "            file.write(line + \"\\n\")\n",
        "            j += 1\n",
        "        file.close()\n",
        "\n",
        "    def parse(self, input_string):\n",
        "        \"\"\"\n",
        "        Parses the given input string using the constructed SLR parse table.\n",
        "\n",
        "        Args:\n",
        "            input_string (list): The input string represented as a list of symbols \n",
        "                (terminals) to be parsed. The end of the input is marked by \"$\".\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the input string is successfully parsed and reaches \n",
        "                the \"Accept\" state; False otherwise.\n",
        "\n",
        "        Notes: This method handles conflicts by always selecting the first operation \n",
        "        in a conflicting cell in the parse table.\n",
        "        \"\"\"\n",
        "        # self.printResultAndGoto()\n",
        "        rows = list(self.state_dict.keys())\n",
        "        cols = self.terminals + [\"$\"] + self.non_terminals\n",
        "        \n",
        "        # appends \"$\" to indicate the end of input.\n",
        "        ls_input = input_string + [\"$\"]\n",
        "        current_char = ls_input[0]\n",
        "        ls_output = []\n",
        "        stack = [0]\n",
        "        while True:\n",
        "            if current_char not in cols:\n",
        "                return False\n",
        "            \n",
        "            row_ind = rows.index(stack[-1])\n",
        "            col_ind = cols.index(current_char)\n",
        "            \n",
        "            operation = self.parse_table[row_ind][col_ind]\n",
        "            \n",
        "            if operation == []:\n",
        "                return False\n",
        "                \n",
        "            else:\n",
        "                operation = operation[0] # just get the first operation in conflict cell\n",
        "                if operation[0] == \"R\":\n",
        "                    rule_num = int(operation[1:])\n",
        "                    current_char = self.grammar[rule_num][0]\n",
        "                    \n",
        "                    # pop stack equal to number of char on rhs of reduce rule\n",
        "                    stack_pop_count = len(self.grammar[rule_num][1])\n",
        "                    stack = stack[:-stack_pop_count]\n",
        "\n",
        "                    ls_output.append(rule_num)\n",
        "                \n",
        "                # goto operation\n",
        "                elif operation[0] == \"G\":\n",
        "                    stack.append(int(operation[1:]))\n",
        "                    current_char = ls_input[0]  \n",
        "                    \n",
        "                # shift operation\n",
        "                elif operation[0] == \"S\":\n",
        "                    stack.append(int(operation[1:]))\n",
        "                    ls_input.pop(0) \n",
        "                    current_char = ls_input[0]      \n",
        "\n",
        "                # accept reached\n",
        "                elif operation == \"Accept\":\n",
        "                    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing table:\n",
            "\n",
            "         +       *       (       )       a       $      E'       E       T       F \n",
            "\n",
            " I0                      S4              S5                      G1      G2      G3\n",
            " I1      S6                                  Accept                                \n",
            " I2      R2      S7              R2              R2                                \n",
            " I3      R4      R4              R4              R4                                \n",
            " I4                      S4              S5                      G8      G2      G3\n",
            " I5      R6      R6              R6              R6                                \n",
            " I6                      S4              S5                              G9      G3\n",
            " I7                      S4              S5                                     G10\n",
            " I8      S6                     S11                                                \n",
            " I9      R1      S7              R1              R1                                \n",
            "I10      R3      R3              R3              R3                                \n",
            "I11      R5      R5              R5              R5                                \n",
            "1\n",
            "[[[], [], ['S4'], [], ['S5'], [], [], ['G1'], ['G2'], ['G3']], [['S6'], [], [], [], [], ['Accept'], [], [], [], []], [['R2'], ['S7'], [], ['R2'], [], ['R2'], [], [], [], []], [['R4'], ['R4'], [], ['R4'], [], ['R4'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], ['G8'], ['G2'], ['G3']], [['R6'], ['R6'], [], ['R6'], [], ['R6'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], [], ['G9'], ['G3']], [[], [], ['S4'], [], ['S5'], [], [], [], [], ['G10']], [['S6'], [], [], ['S11'], [], [], [], [], [], []], [['R1'], ['S7'], [], ['R1'], [], ['R1'], [], [], [], []], [['R3'], ['R3'], [], ['R3'], [], ['R3'], [], [], [], []], [['R5'], ['R5'], [], ['R5'], [], ['R5'], [], [], [], []]]\n",
            "[[[], [], ['S4'], [], ['S5'], [], [], ['G1'], ['G2'], ['G3']], [['S6'], [], [], [], [], ['Accept'], [], [], [], []], [['R2'], ['S7'], [], ['R2'], [], ['R2'], [], [], [], []], [['R4'], ['R4'], [], ['R4'], [], ['R4'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], ['G8'], ['G2'], ['G3']], [['R6'], ['R6'], [], ['R6'], [], ['R6'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], [], ['G9'], ['G3']], [[], [], ['S4'], [], ['S5'], [], [], [], [], ['G10']], [['S6'], [], [], ['S11'], [], [], [], [], [], []], [['R1'], ['S7'], [], ['R1'], [], ['R1'], [], [], [], []], [['R3'], ['R3'], [], ['R3'], [], ['R3'], [], [], [], []], [['R5'], ['R5'], [], ['R5'], [], ['R5'], [], [], [], []]]\n",
            "['a', '+', 'a', '$']\n",
            "### ITERATION 0\n",
            "A -  [<__main__.GSSNode object at 0x000001C937A717D0>]\n",
            "R -  []\n",
            "Q -  []\n",
            "[[[], [], ['S4'], [], ['S5'], [], [], ['G1'], ['G2'], ['G3']], [['S6'], [], [], [], [], ['Accept'], [], [], [], []], [['R2'], ['S7'], [], ['R2'], [], ['R2'], [], [], [], []], [['R4'], ['R4'], [], ['R4'], [], ['R4'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], ['G8'], ['G2'], ['G3']], [['R6'], ['R6'], [], ['R6'], [], ['R6'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], [], ['G9'], ['G3']], [[], [], ['S4'], [], ['S5'], [], [], [], [], ['G10']], [['S6'], [], [], ['S11'], [], [], [], [], [], []], [['R1'], ['S7'], [], ['R1'], [], ['R1'], [], [], [], []], [['R3'], ['R3'], [], ['R3'], [], ['R3'], [], [], [], []], [['R5'], ['R5'], [], ['R5'], [], ['R5'], [], [], [], []]]\n",
            "0 a\n",
            "### OPERATIONS\n",
            "['S5']\n",
            "### SHIFTER\n",
            "[(<__main__.GSSNode object at 0x000001C937A717D0>, 5)]\n",
            "[5]\n",
            "yay\n",
            "GSS tree for iteration 0 saved as gss_tree_iteration_0.png\n",
            "### ITERATION 1\n",
            "A -  [<__main__.GSSNode object at 0x000001C937A7F450>]\n",
            "R -  []\n",
            "Q -  []\n",
            "[[[], [], ['S4'], [], ['S5'], [], [], ['G1'], ['G2'], ['G3']], [['S6'], [], [], [], [], ['Accept'], [], [], [], []], [['R2'], ['S7'], [], ['R2'], [], ['R2'], [], [], [], []], [['R4'], ['R4'], [], ['R4'], [], ['R4'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], ['G8'], ['G2'], ['G3']], [['R6'], ['R6'], [], ['R6'], [], ['R6'], [], [], [], []], [[], [], ['S4'], [], ['S5'], [], [], [], ['G9'], ['G3']], [[], [], ['S4'], [], ['S5'], [], [], [], [], ['G10']], [['S6'], [], [], ['S11'], [], [], [], [], [], []], [['R1'], ['S7'], [], ['R1'], [], ['R1'], [], [], [], []], [['R3'], ['R3'], [], ['R3'], [], ['R3'], [], [], [], []], [['R5'], ['R5'], [], ['R5'], [], ['R5'], [], [], [], []]]\n",
            "5 +\n",
            "### OPERATIONS\n",
            "['R6']\n",
            "A -  []\n",
            "R -  [[<__main__.GSSNode object at 0x000001C937BEFD10>, <__main__.GSSNode object at 0x000001C937A717D0>, 6]]\n",
            "Q -  []\n",
            "### REDUCER\n",
            " [[<__main__.GSSNode object at 0x000001C937BEFD10>, <__main__.GSSNode object at 0x000001C937A717D0>, 6]]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "GSS.find_node_path_length() missing 1 required positional argument: 'length'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 263\u001b[0m\n\u001b[0;32m    261\u001b[0m parser \u001b[38;5;241m=\u001b[39m GLRParser(p\u001b[38;5;241m.\u001b[39mgrammar, p\u001b[38;5;241m.\u001b[39mnon_terminals, p\u001b[38;5;241m.\u001b[39mterminals, p\u001b[38;5;241m.\u001b[39mparse_table)\n\u001b[0;32m    262\u001b[0m input_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma+a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 263\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_string\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[20], line 96\u001b[0m, in \u001b[0;36mGLRParser.parse\u001b[1;34m(self, input_string)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_string):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### ITERATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
            "Cell \u001b[1;32mIn[20], line 118\u001b[0m, in \u001b[0;36mGLRParser.parseword\u001b[1;34m(self, i, input_string)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(i, input_string)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreducer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[20], line 166\u001b[0m, in \u001b[0;36mGLRParser.reducer\u001b[1;34m(self, i, input_string)\u001b[0m\n\u001b[0;32m    163\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar[\u001b[38;5;28mint\u001b[39m(p)][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# for all w such that there exists a path of length 2|p|-1 from x to w do\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m all_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_node_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m all_w:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# operation = self.parse_table(w.state, N)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     col_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbols\u001b[38;5;241m.\u001b[39mindex(N)\n",
            "\u001b[1;31mTypeError\u001b[0m: GSS.find_node_path_length() missing 1 required positional argument: 'length'"
          ]
        }
      ],
      "source": [
        "class GSSNode:\n",
        "    def __init__(self, is_state, state, symbol):\n",
        "        self.is_state = is_state\n",
        "        self.state = state  # Parser state\n",
        "        self.symbol = symbol  # Grammar symbol\n",
        "        self.predecessor_edges = []  # List of edges to predecessor nodes\n",
        "        self.successor_edges = []  # List of edges to successor  nodes\n",
        "\n",
        "    def add_predecessor(self, predecessor):\n",
        "        \"\"\"Add an edge to a predecessor node.\"\"\"\n",
        "        self.predecessor_edges.append(predecessor)\n",
        "\n",
        "    def add_successor(self, successor):\n",
        "        \"\"\"Add an edge to a predecessor node.\"\"\"\n",
        "        self.successor_edges.append(successor)\n",
        "\n",
        "\n",
        "class GSS:\n",
        "    def __init__(self):\n",
        "        self.current_v = 0\n",
        "        self.nodes = {}  # Map v_number -> GSSNode\n",
        "\n",
        "    def create_node(self, is_state, state=-1, symbol=\"\"):\n",
        "        self.current_v += 1\n",
        "        self.nodes[self.current_v] = GSSNode(is_state, state, symbol)\n",
        "        return self.nodes[self.current_v]\n",
        "\n",
        "    def add_edge(self, from_node, to_node):\n",
        "        # successor of v = there is an edge from v to this node \n",
        "        # opposite with edge direction (which is <- in book diagram)\n",
        "        to_node.add_successor(from_node)\n",
        "        from_node.add_predecessor(to_node)\n",
        "\n",
        "    def dfs(self, node, depth):\n",
        "        if depth == 0:\n",
        "            return {node}\n",
        "\n",
        "        reachable = set()\n",
        "        for predecessor in node.predecessor_edges:\n",
        "            reachable |= self.dfs(predecessor, depth - 1)\n",
        "        return reachable\n",
        "\n",
        "    def find_node_path_length(self, start, length):\n",
        "        # Find all nodes reachable from `start` with a path of a specific length.\n",
        "        return self.dfs(start, length)\n",
        "\n",
        "    def path_exists(self, start, end, length):\n",
        "        # Check if a path of a specific length exists between `start` and `end`.\n",
        "        reachable_nodes = self.find_path_length(start, length)\n",
        "        return end in reachable_nodes\n",
        "\n",
        "\n",
        "class GLRParser():\n",
        "    def __init__(self, grammar, non_terminals, terminals, parse_table): \n",
        "        self.grammar = grammar\n",
        "        self.non_terminals = non_terminals\n",
        "        self.terminals = terminals\n",
        "        self.symbols = self.terminals + [\"$\"] + self.non_terminals\n",
        "        self.parse_table = self.load_parse_table(parse_table)\n",
        "        print(self.parse_table)\n",
        "\n",
        "        self.gss = GSS()\n",
        "        self.root_node = self.gss.create_node(True, state=0)  # Initial state\n",
        "        self.input_string = []\n",
        "        self.r = False\n",
        "        self.U = {0: [self.root_node]}\n",
        "        self.R = []\n",
        "        self.Q = []\n",
        "        self.A = []\n",
        "\n",
        "    def load_parse_table(self, parse_table):\n",
        "        print(1)\n",
        "        print(parse_table)\n",
        "\n",
        "        parse_table_dict = {}\n",
        "        header = self.terminals + [\"$\"] + self.non_terminals\n",
        "\n",
        "        state = 0\n",
        "        for row in parse_table:\n",
        "            for col, value in enumerate(row):\n",
        "                if value:\n",
        "                    parse_table_dict[(state, header[col])] = value\n",
        "            state += 1\n",
        "        return parse_table\n",
        "\n",
        "\n",
        "    def parse(self, input_string):\n",
        "        \"\"\"Main parsing loop.\"\"\"\n",
        "        self.input_string = input_string\n",
        "        self.input_string.append(\"$\")\n",
        "\n",
        "        i = 0\n",
        "        print(self.input_string)\n",
        "        while i < len(self.input_string):\n",
        "            print(\"### ITERATION\", i)\n",
        "            self.parseword(i, input_string)\n",
        "            i += 1\n",
        "\n",
        "        if self.r == True:\n",
        "            print(\"Input accepted!\")\n",
        "        else:\n",
        "            print(\"Input not accepted!\")\n",
        "        return self.r\n",
        "\n",
        "\n",
        "    def parseword(self, i, input_string):\n",
        "        self.A = copy.deepcopy(self.U[i])\n",
        "        self.R = []\n",
        "        self.Q = []\n",
        "\n",
        "        while True:\n",
        "            print(\"A - \", self.A)\n",
        "            print(\"R - \", self.R)\n",
        "            print(\"Q - \", self.Q)\n",
        "            if len(self.A) != 0:\n",
        "                self.actor(i, input_string)\n",
        "            elif len(self.R) != 0:\n",
        "                self.reducer(i, input_string)\n",
        "\n",
        "            if len(self.R) == 0 and len(self.A) == 0:\n",
        "                break\n",
        "\n",
        "        self.shifter(i, input_string)\n",
        "\n",
        "        draw_gss_tree(self.gss, i)\n",
        "\n",
        "\n",
        "\n",
        "    def actor(self, i, input_string):\n",
        "        v = self.A.pop(0)\n",
        "            \n",
        "        current_state = v.state\n",
        "        symbol = input_string[i]\n",
        "        col_ind = self.symbols.index(symbol)\n",
        "        print(self.parse_table)\n",
        "\n",
        "        print(current_state, symbol)\n",
        "        if self.parse_table[current_state][col_ind]:\n",
        "        # if (current_state, symbol) in self.parse_table:\n",
        "            operations = self.parse_table[current_state][col_ind]\n",
        "            print(\"### OPERATIONS\")    \n",
        "            print(operations)\n",
        "            for operation in operations:\n",
        "                if len(operation) == 0:\n",
        "                    return\n",
        "                \n",
        "                if operation[0] == \"Accept\":\n",
        "                    self.r = True\n",
        "                elif operation[0] == \"S\":\n",
        "                    self.Q.append((v, int(operation[1:])))\n",
        "                elif operation[0] == \"R\":\n",
        "                    # for all x such that x SUCCESSORS(v), add [v, x, p] to R.\n",
        "                    for key in self.gss.nodes.keys():\n",
        "                        if current_state == self.gss.nodes[key].state:\n",
        "                            v = self.gss.nodes[key]\n",
        "                            for x in v.successor_edges:\n",
        "                                self.R.append([v, x, int(operation[1:])])\n",
        "\n",
        "    \n",
        "    def reducer(self, i, input_string):\n",
        "        print(\"### REDUCER\\n\", self.R)\n",
        "        (v, x, p) = self.R.pop(0)\n",
        "        N = self.grammar[int(p)][0]\n",
        "\n",
        "        # for all w such that there exists a path of length 2|p|-1 from x to w do\n",
        "        all_w = self.gss.find_node_path_length(2*int(p)-1)\n",
        "        for w in all_w:\n",
        "            # operation = self.parse_table(w.state, N)\n",
        "            col_ind = self.symbols.index(N)\n",
        "            for operation in self.parse_table[w.state][col_ind]:\n",
        "                if len(operation) == 0:\n",
        "                    return\n",
        "                elif operation[0] == \"G\":\n",
        "                    s = int(operation[1:])\n",
        "                # else:\n",
        "                #     return\n",
        "             \n",
        "\n",
        "            # if there exists u such that u in U_i and STATE(u) = s then\n",
        "            need_create_reduce = False\n",
        "            for u in self.U[i]:\n",
        "                if u.state == s:\n",
        "                    need_create_reduce = True\n",
        "                    break\n",
        "                    \n",
        "            # if there exists u such that u in U_i and STATE(u) = s then\n",
        "            if need_create_reduce:\n",
        "                # if there already exists a path of length 2 from u to w then\n",
        "                if self.gss.path_exists(u, w, 2):\n",
        "                    continue\n",
        "                else:\n",
        "                    # if u in A\n",
        "                    # for all q such that reduce q in ACTION(STATE(u),ai+1)\n",
        "                    # add (u,z,q) to R.\n",
        "                    z = self.gss.create_node(False, symbol=N)\n",
        "                    self.gss.add_edge(u, z)\n",
        "                    self.gss.add_edge(z, w)\n",
        "\n",
        "                    if u not in self.A:\n",
        "                        col_ind = self.symbols.index(input_string[i])\n",
        "                        for operation in self.parse_table[u.state][col_ind]:\n",
        "                        # for operation in self.parse_table(u.state, input_string[i]):\n",
        "                            if operation[0] == \"R\":\n",
        "                                self.R.append((u, z, int(operation[1:])))\n",
        "\n",
        "            else:\n",
        "                u = self.gss.create_node(True, state=s)\n",
        "                z = self.gss.create_node(False, symbol=N)\n",
        "\n",
        "                self.gss.add_edge(u, z)\n",
        "                self.gss.add_edge(z, w)\n",
        "\n",
        "                self.A.append(u)\n",
        "                self.U[i].append(u)\n",
        "                        \n",
        "                    \n",
        "    \n",
        "\n",
        "    def shifter(self, i, input_string):\n",
        "        print(\"### SHIFTER\")\n",
        "        print(self.Q)\n",
        "        all_s = list(set([s for v, s in self.Q]))\n",
        "        print(all_s)\n",
        "        for state in all_s:\n",
        "            # new state node after shift\n",
        "            w = self.gss.create_node(True, state=state)\n",
        "\n",
        "            # add w to U_i+1\n",
        "            if i+1 not in self.U.keys():\n",
        "                self.U[i+1] = []\n",
        "            self.U[i+1].append(w)\n",
        "\n",
        "            # add edge between w and v in <v,s> with the s above\n",
        "            all_v = list(set([v for v, s in self.Q if s == state]))\n",
        "            for v in all_v:\n",
        "                x = self.gss.create_node(False, symbol=input_string[i])\n",
        "                self.gss.add_edge(w, x)\n",
        "                self.gss.add_edge(v, w)\n",
        "\n",
        "\n",
        "# Example 1 Grammar and Tables\n",
        "grammar = {\n",
        "    \"E\": [\n",
        "            [\"E\", \"+\", \"T\"],       # Rule 1: E → E + T\n",
        "            [\"T\"]                  # Rule 2: E → T\n",
        "            ],        \n",
        "    \"T\": [\n",
        "            [\"T\", \"*\", \"F\"],       # Rule 3: T → T * F\n",
        "            [\"F\"]                  # Rule 4: T → F\n",
        "            ],           \n",
        "    \"F\": [\n",
        "            [\"(\", \"E\", \")\"],       # Rule 5: F → ( E )\n",
        "            [\"a\"]                  # Rule 6: F → a\n",
        "            ]\n",
        "}\n",
        "\n",
        "start = \"E\"\n",
        "\n",
        "# Test the Parser\n",
        "p = SLRParser(grammar, start)\n",
        "parser = GLRParser(p.grammar, p.non_terminals, p.terminals, p.parse_table)\n",
        "input_string = list(\"a+a\")\n",
        "parser.parse(input_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def draw_gss_tree(gss, iteration):\n",
        "    \"\"\"\n",
        "    Visualize the GSS tree using Graphviz.\n",
        "    \n",
        "    :param gss: The GSS instance to visualize.\n",
        "    :param iteration: The current parseword iteration to label the output.\n",
        "    \"\"\"\n",
        "    print(\"yay\")\n",
        "    dot = Digraph()\n",
        "    dot.attr(rankdir=\"LR\")  # Left-to-right layout\n",
        "    \n",
        "    # Add nodes\n",
        "    for node_id, node in gss.nodes.items():\n",
        "        label = f\"ID: {node_id}\\nState: {node.state}\\nSymbol: {node.symbol}\"\n",
        "        shape = \"circle\" if node.is_state else \"box\"\n",
        "        dot.node(str(node_id), label, shape=shape)\n",
        "    \n",
        "    # Add edges\n",
        "    for node_id, node in gss.nodes.items():\n",
        "        for pred in node.predecessor_edges:\n",
        "            dot.edge(str(node_id), str(pred))\n",
        "    \n",
        "    # Render and save\n",
        "    filename = f\"gss_tree_iteration_{iteration}\"\n",
        "    dot.render(filename, format=\"png\", cleanup=True)\n",
        "    print(f\"GSS tree for iteration {iteration} saved as {filename}.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
